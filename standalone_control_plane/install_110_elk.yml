---
- name: Install ELK Stack on Kubernetes
  hosts: k3s_control_plane
  become: true
  gather_facts: true
  vars:
    # Kubeconfig settings
    kubeconfig_path: "{{ playbook_dir }}/fetched_tokens/k3s-kubeconfig"
    node_ip: "{{ ansible_default_ipv4.address }}"
    
    # Delegation settings
    delegate_host: "{{ groups['utility'][0] }}"  # First host in the utility group
    
    # Namespace and component deployment flags
    elk_namespace: elk-stack
    deploy_elasticsearch: true
    deploy_kibana: true
    deploy_logstash: true
    
    # Release names for components
    elasticsearch_release_name: elasticsearch
    kibana_release_name: kibana
    logstash_release_name: logstash
    
    # Component versions
    elasticsearch_version: "8.12.0"
    kibana_version: "8.12.0"
    logstash_version: "8.12.0"
    
    # Security settings
    elasticsearch_security_enabled: true
    elastic_password: "{{ lookup('password', '/dev/null chars=ascii_letters,digits length=16') }}"  # Random password
    elastic_default_password: "changeme"  # Fallback password
    
    # Elasticsearch settings
    elasticsearch_cluster_name: "k3s-elk"
    elasticsearch_replicas: 1
    elasticsearch_heap_size: "1g"
    elasticsearch_cpu_request: "100m"
    elasticsearch_memory_request: "1Gi" 
    elasticsearch_cpu_limit: "1000m"
    elasticsearch_memory_limit: "2Gi"
    elasticsearch_storage_size: "10Gi"
    elasticsearch_protocol: "http"  # Change to https if security is enabled and you want SSL
    
    # Kibana settings
    kibana_replicas: 1
    kibana_cpu_request: "100m"
    kibana_memory_request: "512Mi"
    kibana_cpu_limit: "500m"
    kibana_memory_limit: "1Gi"
    
    # Logstash settings
    logstash_replicas: 1
    logstash_heap_size: "1g"
    logstash_cpu_request: "100m"
    logstash_memory_request: "512Mi"
    logstash_cpu_limit: "500m"
    logstash_memory_limit: "1Gi"
    logstash_persistence_enabled: false
    logstash_storage_size: "2Gi"
    logstash_monitoring_enabled: true
    create_default_logstash_pipeline: true
    create_logstash_configmap: true
    
    # Traefik integration
    traefik_namespace: kube-system
    
    # Storage configuration (uncomment and set if needed)
    # elasticsearch_storage_class: "local-path"
    # logstash_storage_class: "local-path"
    
    # Cleanup options
    clean_install: false  # Set to true to remove any existing ELK stack before installation
    
  tasks:
    - name: Ensure directories exist
      file:
        path: "{{ item }}"
        state: directory
        mode: '0755'
      loop:
        - "{{ playbook_dir }}/fetched_tokens"
      delegate_to: "{{ groups['utility'][0] }}"
      become: false
      
    - name: Check if kubeconfig exists
      stat:
        path: "{{ kubeconfig_path }}"
      register: kubeconfig_stat
      delegate_to: "{{ groups['utility'][0] }}"
      become: false

    - name: Fetch kubeconfig from k3s server if not exists
      ansible.builtin.fetch:
        src: /etc/rancher/k3s/k3s.yaml
        dest: "{{ kubeconfig_path }}"
        flat: yes
      when: not kubeconfig_stat.stat.exists
      
    - name: Update kubeconfig server address if newly created
      ansible.builtin.replace:
        path: "{{ kubeconfig_path }}"
        regexp: 'https://127.0.0.1:6443'
        replace: 'https://{{ node_ip }}:6443'
      delegate_to: "{{ groups['utility'][0] }}"
      become: false
      when: not kubeconfig_stat.stat.exists
      
    - name: Verify kubeconfig exists
      stat:
        path: "{{ kubeconfig_path }}"
      register: kubeconfig_verify
      delegate_to: "{{ groups['utility'][0] }}"
      become: false
      
    - name: Fail if kubeconfig doesn't exist
      fail:
        msg: "Kubeconfig file not found at {{ kubeconfig_path }}. Check permissions and connectivity."
      when: not kubeconfig_verify.stat.exists
      delegate_to: "{{ groups['utility'][0] }}"
      become: false

    # Clean up existing installation if clean_install is true
    - name: Check if ELK namespace exists
      kubernetes.core.k8s_info:
        kind: Namespace
        name: "{{ elk_namespace }}"
        kubeconfig: "{{ kubeconfig_path }}"
      register: elk_namespace_check
      delegate_to: "{{ groups['utility'][0] }}"
      become: false
      ignore_errors: true
      
    - name: Remove existing ELK Stack Helm releases if clean install requested
      kubernetes.core.helm:
        name: "{{ item }}"
        kubeconfig: "{{ kubeconfig_path }}"
        release_namespace: "{{ elk_namespace }}"
        state: absent
        wait: true
      with_items:
        - "{{ kibana_release_name }}"
        - "{{ logstash_release_name }}"
        - "{{ elasticsearch_release_name }}"
      delegate_to: "{{ groups['utility'][0] }}"
      become: false
      when: 
        - clean_install | bool
        - elk_namespace_check.resources is defined
        - elk_namespace_check.resources | length > 0
      ignore_errors: true
      
    - name: Delete ELK namespace if clean install requested
      kubernetes.core.k8s:
        kubeconfig: "{{ kubeconfig_path }}"
        name: "{{ elk_namespace }}"
        api_version: v1
        kind: Namespace
        state: absent
        wait: true
      delegate_to: "{{ groups['utility'][0] }}"
      become: false
      when: 
        - clean_install | bool
        - elk_namespace_check.resources is defined 
        - elk_namespace_check.resources | length > 0
      ignore_errors: true
      
    - name: Wait for namespace deletion if cleaning up
      pause:
        seconds: 10
      when: 
        - clean_install | bool
        - elk_namespace_check.resources is defined
        - elk_namespace_check.resources | length > 0
        
    # Include ELK stack role with delegation set in variables
    - name: Include ELK Stack role
      include_role:
        name: elk_stack
      vars:
        delegate_host: "{{ delegate_host }}"
        
    # Post-installation validation
    - name: Validate Elasticsearch is accessible
      kubernetes.core.k8s_exec:
        namespace: "{{ elk_namespace }}"
        pod: "{{ elasticsearch_release_name }}-master-0"
        command: curl -s -XGET http://localhost:9200/_cluster/health
        kubeconfig: "{{ kubeconfig_path }}"
      register: es_health
      delegate_to: "{{ groups['utility'][0] }}"
      become: false
      ignore_errors: true
      when: deploy_elasticsearch | bool
      
    - name: Get Traefik NodePort
      shell: >
        kubectl --kubeconfig="{{ kubeconfig_path }}" get svc traefik -n {{ traefik_namespace }} 
        -o jsonpath='{.spec.ports[?(@.name=="web")].nodePort}'
      delegate_to: "{{ groups['utility'][0] }}"
      become: false
      register: traefik_nodeport
      changed_when: false
      ignore_errors: true
        
    # Display final information
    - name: Display ELK Stack access information
      debug:
        msg:
          - "=============================================================="
          - "                   ELK Stack Deployment                       "
          - "=============================================================="
          - "Deployment Status:"
          - "- Elasticsearch: {{ 'Deployed' if deploy_elasticsearch else 'Skipped' }}"
          - "- Kibana: {{ 'Deployed' if deploy_kibana else 'Skipped' }}"
          - "- Logstash: {{ 'Deployed' if deploy_logstash else 'Skipped' }}"
          - ""
          - "Access Information:"
          - "- Kibana URL: http://{{ node_ip }}:{{ traefik_nodeport.stdout | default('nodeport_not_found') }}/kibana"
          - "- Elasticsearch REST API: http://{{ node_ip }}:{{ traefik_nodeport.stdout | default('nodeport_not_found') }}/elasticsearch (not configured by default)"
          - ""
          - "Credentials (if security is enabled):"
          - "- Username: elastic"
          - "- Password: {{ elastic_password }}"
          - ""
          - "Cluster Health: {{ (es_health.stdout | default('{}') | from_json).status | default('Unknown') if deploy_elasticsearch and not es_health.failed else 'Not checked' }}"
          - ""
          - "Next Steps:"
          - "1. Access Kibana at the URL above and log in with the credentials"
          - "2. Create index patterns to start analyzing your logs"
          - "3. To set up log shipping, configure Filebeat on your nodes"
          - ""
          - "To clean up this installation:"
          - "ansible-playbook cleanup_110_elk.yml"
          - "=============================================================="